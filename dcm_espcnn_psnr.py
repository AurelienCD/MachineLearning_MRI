# -*- coding: utf-8 -*-
"""DCM_ESPCNN-PSNR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SXtD6vBjBBBjZ0Mr2VWg29asBDhyZF40
"""

!pip install tensorflow_io

"""# Super-Résolution des scans IRMs du cerveau

Ce notebook contient les étapes pour préparer les images Dicom (regroupées en 3 dossiers : images d'apprentissage, de validation et de test), les entraîner avec un modèle convolutionnel de super-résolution appelé ESPCNN (Efficient Sub-Pixel Convolutional Neural Network) : https://arxiv.org/pdf/1609.05158.pdf

Les images utilisées pour ce modèle ont été téléchargé sur Google Drive. Pour réexecuter ce code, il faut utiliser Google Colab et monter votre Google Drive sur Colab en choisissant un type d'exécution sur GPU et téléchargez les images en respectant les chemins '../train' pour données d'apprentissage, '../val' pour données de validation, '../test' pour données de test. (à vérifier les variables des chemins dans le code)

Les meilleurs poids appris du modèle sont enregistrés, et les images de test sont visualisées avec les images d'entrée, et les images de vérité terrain pour observer les performances du modèle.

Le paramètre d'augmentation de résolution est de 2 pour cet exemple (la variable upscale_factor). La taille des images est fixée sur (380,300) alors l'image d'entrée est de taille (190,150), ces paramètres peuvent changer.

**Remarque** Les images dicom utilisées sont des données publiques disponibles sur https://fastmri.org/dataset/ <br>
Un ensemble de 500 images (200 train, 200 val, 100 test) de type T2 a été choisi pour réaliser ce travail. <br> 
Lien pour télécharger ce dataset personnalisé : https://drive.google.com/file/d/1wTcX5TjDRaAuR-x6g283en7bWJPwKYIo/view?usp=sharing
"""

upscale_factor=2

from google.colab import drive
drive.mount("/content/drive")

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import tensorflow_io as tfio

import pathlib
import os
import math
import numpy as np

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import array_to_img
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.preprocessing import image_dataset_from_directory

from IPython.display import display

# %matplotlib inline
from matplotlib import pyplot as plt

"""###Préparation des données d'apprentissage, de validation et de test

Le chemin du dossier principal contenant les 3 sous dossiers (train, val et test) est dans la variable 'directory'
"""

directory='./drive/MyDrive/MRI-SR/'

ds_train = tf.data.Dataset.list_files(str(pathlib.Path(directory+'train/'+'*.dcm')))

def process_path(file_path):
  image_bytes=tf.io.read_file(file_path)
  image=tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint32)
  return image[0,:,:,:]

ds_train=ds_train.map(process_path)

ds_valid = tf.data.Dataset.list_files(str(pathlib.Path(directory+'val/'+'*.dcm')))

ds_valid=ds_valid.map(process_path)

def casting(input_image):
    input_image = tf.cast(input_image, tf.float32)
    return input_image

ds_train=ds_train.map(casting)
ds_valid=ds_valid.map(casting)

def process_input(input):
    return tf.image.resize(input, [190, 150], method="area")


def process_target(input):
    return tf.image.resize(input, [380, 300], method="bicubic")


ds_train = ds_train.map(
    lambda x: (process_input(x), process_target(x))
)
ds_train = ds_train.prefetch(buffer_size=32)

ds_valid = ds_valid.map(
    lambda x: (process_input(x), process_target(x))
)
ds_valid = ds_valid.prefetch(buffer_size=32)

"""Une taille de batch de 8 est sélectionnée pour l'apprentissage et la validation"""

ds_train=ds_train.batch(8)
ds_valid=ds_valid.batch(8)

"""###Visualisation du 1er Batch

Les images d'entrées et les images cibles sont stockées dans le batch d'apprentissage (ds_train), visualisons le 1er batch (contenat 8 images de basse résolution, et 8 images de haute résolution) :
"""

for batch in ds_train.take(1):
    for img in batch[0]:
        display(array_to_img(img))
    for img in batch[1]:
        display(array_to_img(img))

"""Les chemins des images de test sont stockées dans une liste"""

test_path = os.path.join(directory, "test")

test_img_paths = sorted(
    [
        os.path.join(test_path, fname)
        for fname in os.listdir(test_path)
        if fname.endswith(".dcm")
    ]
)
#needs dicom decoder to be read at test

"""###Définition du modèle

L'architecture du réseau utilisé est la suivante :

<img src="https://miro.medium.com/max/2400/1*AnTunkGkz-KNTQkrezoSmQ.jpeg" alt="Architecture de ESPCNN">

Toutes les couches (à part la dernière) sont des couches de convolution qui vont obtenir les "feature maps" de l'image d'entrée de basse résolution, et la dernière couche est la couche convolutionnelle qui va construire l'image résultat avec le paramètre d'augmentation de résolution choisi.
"""

def get_model(upscale_factor=2, channels=1):
    conv_args = {
        "activation": "relu",
        "kernel_initializer": "Orthogonal",
        "padding": "same",
    }

    inputs = keras.Input(shape=(None, None, channels))
    x = layers.Conv2D(64, 5, **conv_args)(inputs)
    x = layers.Conv2D(64, 3, **conv_args)(x)
    x = layers.Conv2D(32, 3, **conv_args)(x)
    x = layers.Conv2D(channels * (upscale_factor ** 2), 3, **conv_args)(x)
    outputs = tf.nn.depth_to_space(x, upscale_factor)

    return keras.Model(inputs, outputs)

"""###Définition des callbacks, optimiseur et fonction de coût

La fonction de coût utilisée est l'erreur quadratique moyenne, et pour l'optimiseur Adam est choisi avec un taux d'apprentissage de 0.001
"""

import datetime
from keras.callbacks import ModelCheckpoint
checkpoint = ModelCheckpoint("./drive/MyDrive/checkpoint/best_model.hdf5", monitor='loss', verbose=0, save_best_only=True, mode='auto', period=1)

path = "./drive/MyDrive/newfile/logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=path,histogram_freq=1)

model = get_model(upscale_factor=upscale_factor, channels=1)
model.summary()

callbacks = [checkpoint, tensorboard_callback]
loss_fn = keras.losses.MeanSquaredError()
optimizer = keras.optimizers.Adam(learning_rate=0.001)

"""###Apprentissage

Apprentissage du modèle sur 50 époches
"""

epochs = 50

model.compile(optimizer=optimizer, loss=loss_fn,)

model.fit(ds_train, epochs=epochs, validation_data=ds_valid, callbacks=[checkpoint, tensorboard_callback])

"""###Visualisation de l'erreur sur les données d'apprentissage et de validation"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir ./drive/MyDrive/newfile/logs/fit

"""Sauvegarde du modèle avec les meilleurs poids dans le chemin donné :"""

model.save('./drive/MyDrive/newfile/MRI-SR/model/')

"""Pour récupérer les poids du modèle sauvegardé :

from tensorflow import keras
model = keras.models.load_model('path/to/location')

###Test du modèle et visualization des images prédites en comparrant avec les images basse résolution et les images haute résolution

le PSNR affiché dans la visualisation n'est pas exacte parce ce qu'il dépend de la valeur maximale des pixels (calculée pour l'ensemble de test dans un bloc qui suit)
"""

def get_lowres_image(img, upscale_factor):
    return tf.image.resize(img, [190, 150], method='bicubic')

"""Pour tester plus d'image, changez l'indice de slicing de test_img_paths (il existe 100 images de test au total)"""

total_bicubic_psnr = 0.0
total_test_psnr = 0.0

lowres=[]
highres=[]
predict=[]
for index, test_img_path in enumerate(test_img_paths[0:5]):
    image_bytes=tf.io.read_file(test_img_path)
    image=tfio.image.decode_dicom_image(image_bytes, dtype=tf.uint32)
    image = tf.cast(image, tf.float32)
    img = tf.image.resize(image,[190,150],method='area')
    pred=model.predict(img)


    lowres_input=get_lowres_image(img, upscale_factor)
    w = lowres_input.shape[1] * upscale_factor
    h = lowres_input.shape[2] * upscale_factor

    highres_img = tf.image.resize(image,[380,300],method='bicubic')

    lowres_img = tf.image.resize(lowres_input,[w, h])
    lowres_img_arr = img_to_array(np.squeeze(lowres_img))
    highres_img_arr = img_to_array(np.squeeze(highres_img))
    predict_img_arr = img_to_array(np.squeeze(pred))

    lowres.append(lowres_img_arr)
    highres.append(highres_img_arr)
    predict.append(predict_img_arr)

    bicubic_psnr = tf.image.psnr(lowres_img_arr, highres_img_arr, max_val=np.amax(np.squeeze(highres_img))) #valeur max prise de la prochaine section (dépend du pixel max)
    test_psnr = tf.image.psnr(predict_img_arr, highres_img_arr, max_val=np.amax(np.squeeze(highres_img)))

    print("PSNR of low resolution image and high resolution image is %.4f" % bicubic_psnr)
    print("PSNR of predict and high resolution is %.4f" % test_psnr)

    display(array_to_img(lowres_img[0,:,:,:]))
    display(array_to_img(highres_img[0,:,:,:]))
    display(array_to_img(pred[0,:,:,:]))    

    #bicubic_psnr = tf.image.psnr(lowres_img_arr, highres_img_arr, max_val=1782.0515) #valeur max prise de la prochaine section (dépend du pixel max)
    #test_psnr = tf.image.psnr(predict_img_arr, highres_img_arr, max_val=1782.0515)

    total_bicubic_psnr += bicubic_psnr
    total_test_psnr += test_psnr

    

print("Avg. PSNR of lowres images is %.4f" % (total_bicubic_psnr / 5)) # changer le dénominateur par le nombre d'exemple de test calculée
print("Avg. PSNR of reconstructions is %.4f" % (total_test_psnr / 5)) # changer le dénominateur par le nombre d'exemple de test calculée

lowres=np.array(lowres)
highres=np.array(highres)
predict=np.array(predict)

"""###Comparaison des images

Chaque ligne représente l'image de basse résolution, suivi de l'image haute résolution, suivi de l'image prédite pour les données de test
"""

for i in range(len(predict)):
  
  fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(25,25))
  ax1.imshow(np.squeeze(lowres[i]),cmap='gray')
  ax2.imshow(np.squeeze(highres[i]),cmap='gray')
  ax3.imshow(np.squeeze(predict[i]),cmap='gray')

